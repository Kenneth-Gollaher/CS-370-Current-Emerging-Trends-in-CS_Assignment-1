{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 83s 2ms/step - loss: 1.7430 - accuracy: 0.3898 - val_loss: 1.3687 - val_accuracy: 0.5111\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 77s 2ms/step - loss: 1.3625 - accuracy: 0.5178 - val_loss: 1.2407 - val_accuracy: 0.5607\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 81s 2ms/step - loss: 1.2354 - accuracy: 0.5659 - val_loss: 1.2190 - val_accuracy: 0.5818\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 82s 2ms/step - loss: 1.1484 - accuracy: 0.5952 - val_loss: 1.1440 - val_accuracy: 0.5991\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 83s 2ms/step - loss: 1.0848 - accuracy: 0.6218 - val_loss: 1.1283 - val_accuracy: 0.6110\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 82s 2ms/step - loss: 1.0218 - accuracy: 0.6423 - val_loss: 1.0468 - val_accuracy: 0.6351\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 83s 2ms/step - loss: 0.9805 - accuracy: 0.6599 - val_loss: 1.1571 - val_accuracy: 0.6023\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 82s 2ms/step - loss: 0.9405 - accuracy: 0.6701 - val_loss: 1.0047 - val_accuracy: 0.6585\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 83s 2ms/step - loss: 0.8904 - accuracy: 0.6908 - val_loss: 1.0648 - val_accuracy: 0.6444\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 86s 2ms/step - loss: 0.8606 - accuracy: 0.7019 - val_loss: 1.0950 - val_accuracy: 0.6393\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.8349 - accuracy: 0.7092 - val_loss: 0.9899 - val_accuracy: 0.6655\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.8009 - accuracy: 0.7243 - val_loss: 1.0061 - val_accuracy: 0.6660\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.7683 - accuracy: 0.7320 - val_loss: 0.9935 - val_accuracy: 0.6680\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 81s 2ms/step - loss: 0.7446 - accuracy: 0.7438 - val_loss: 1.0594 - val_accuracy: 0.6573\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 81s 2ms/step - loss: 0.7265 - accuracy: 0.7461 - val_loss: 1.0036 - val_accuracy: 0.6751\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 82s 2ms/step - loss: 0.6993 - accuracy: 0.7593 - val_loss: 1.0247 - val_accuracy: 0.6705\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 82s 2ms/step - loss: 0.6845 - accuracy: 0.7638 - val_loss: 1.0696 - val_accuracy: 0.6696\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 83s 2ms/step - loss: 0.6611 - accuracy: 0.7702 - val_loss: 1.0453 - val_accuracy: 0.6682\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 82s 2ms/step - loss: 0.6439 - accuracy: 0.7779 - val_loss: 1.0475 - val_accuracy: 0.6781\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 82s 2ms/step - loss: 0.6293 - accuracy: 0.7846 - val_loss: 1.0694 - val_accuracy: 0.6803\n",
      "10000/10000 [==============================] - 9s 881us/step\n",
      "Test score: 1.0887539552688599\n",
      "Test accuracy: 0.6672000288963318\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 Simple Network at 20 iterations\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-10 Simple Network at 20 iterations\n",
    "##### Training Set: 78.46%\n",
    "##### Validation: 68.03%\n",
    "##### Test Accuracy: 66.72%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "40000/40000 [==============================] - 228s 6ms/step - loss: 1.8018 - accuracy: 0.3469 - val_loss: 1.3944 - val_accuracy: 0.4921\n",
      "Epoch 2/40\n",
      "40000/40000 [==============================] - 219s 5ms/step - loss: 1.3413 - accuracy: 0.5243 - val_loss: 1.1710 - val_accuracy: 0.5882\n",
      "Epoch 3/40\n",
      "40000/40000 [==============================] - 224s 6ms/step - loss: 1.1197 - accuracy: 0.6066 - val_loss: 0.9971 - val_accuracy: 0.6506\n",
      "Epoch 4/40\n",
      "40000/40000 [==============================] - 218s 5ms/step - loss: 0.9824 - accuracy: 0.6574 - val_loss: 0.9331 - val_accuracy: 0.6759\n",
      "Epoch 5/40\n",
      "40000/40000 [==============================] - 219s 5ms/step - loss: 0.8871 - accuracy: 0.6892 - val_loss: 0.8647 - val_accuracy: 0.6978\n",
      "Epoch 6/40\n",
      "40000/40000 [==============================] - 225s 6ms/step - loss: 0.8200 - accuracy: 0.7150 - val_loss: 0.8502 - val_accuracy: 0.7037\n",
      "Epoch 7/40\n",
      "40000/40000 [==============================] - 229s 6ms/step - loss: 0.7646 - accuracy: 0.7351 - val_loss: 0.7920 - val_accuracy: 0.7296\n",
      "Epoch 8/40\n",
      "40000/40000 [==============================] - 229s 6ms/step - loss: 0.7103 - accuracy: 0.7546 - val_loss: 0.9728 - val_accuracy: 0.6812\n",
      "Epoch 9/40\n",
      "40000/40000 [==============================] - 233s 6ms/step - loss: 0.6764 - accuracy: 0.7675 - val_loss: 0.7931 - val_accuracy: 0.7331\n",
      "Epoch 10/40\n",
      "40000/40000 [==============================] - 243s 6ms/step - loss: 0.6475 - accuracy: 0.7779 - val_loss: 0.7239 - val_accuracy: 0.7662\n",
      "Epoch 11/40\n",
      "40000/40000 [==============================] - 241s 6ms/step - loss: 0.6222 - accuracy: 0.7868 - val_loss: 0.9146 - val_accuracy: 0.7230\n",
      "Epoch 12/40\n",
      "40000/40000 [==============================] - 211s 5ms/step - loss: 0.6004 - accuracy: 0.7940 - val_loss: 0.8469 - val_accuracy: 0.7539\n",
      "Epoch 13/40\n",
      "40000/40000 [==============================] - 187s 5ms/step - loss: 0.5888 - accuracy: 0.7993 - val_loss: 0.8316 - val_accuracy: 0.7500\n",
      "Epoch 14/40\n",
      "40000/40000 [==============================] - 192s 5ms/step - loss: 0.5748 - accuracy: 0.8049 - val_loss: 0.7355 - val_accuracy: 0.7509\n",
      "Epoch 15/40\n",
      "40000/40000 [==============================] - 175s 4ms/step - loss: 0.5626 - accuracy: 0.8105 - val_loss: 0.7279 - val_accuracy: 0.7719\n",
      "Epoch 16/40\n",
      "40000/40000 [==============================] - 167s 4ms/step - loss: 0.5586 - accuracy: 0.8137 - val_loss: 0.8961 - val_accuracy: 0.7766\n",
      "Epoch 17/40\n",
      "40000/40000 [==============================] - 193s 5ms/step - loss: 0.5549 - accuracy: 0.8151 - val_loss: 0.6802 - val_accuracy: 0.7805\n",
      "Epoch 18/40\n",
      "40000/40000 [==============================] - 223s 6ms/step - loss: 0.5546 - accuracy: 0.8186 - val_loss: 0.7166 - val_accuracy: 0.7785\n",
      "Epoch 19/40\n",
      "40000/40000 [==============================] - 255s 6ms/step - loss: 0.5397 - accuracy: 0.8210 - val_loss: 0.7292 - val_accuracy: 0.7923\n",
      "Epoch 20/40\n",
      "40000/40000 [==============================] - 241s 6ms/step - loss: 0.5406 - accuracy: 0.8235 - val_loss: 0.7770 - val_accuracy: 0.7829\n",
      "Epoch 21/40\n",
      "40000/40000 [==============================] - 283s 7ms/step - loss: 0.5336 - accuracy: 0.8230 - val_loss: 0.7287 - val_accuracy: 0.7818\n",
      "Epoch 22/40\n",
      "40000/40000 [==============================] - 284s 7ms/step - loss: 0.5310 - accuracy: 0.8224 - val_loss: 0.7316 - val_accuracy: 0.7696\n",
      "Epoch 23/40\n",
      "40000/40000 [==============================] - 287s 7ms/step - loss: 0.5299 - accuracy: 0.8248 - val_loss: 0.7810 - val_accuracy: 0.7757\n",
      "Epoch 24/40\n",
      "40000/40000 [==============================] - 253s 6ms/step - loss: 0.5290 - accuracy: 0.8278 - val_loss: 0.7761 - val_accuracy: 0.7807\n",
      "Epoch 25/40\n",
      "40000/40000 [==============================] - 256s 6ms/step - loss: 0.5298 - accuracy: 0.8291 - val_loss: 0.8410 - val_accuracy: 0.7712\n",
      "Epoch 26/40\n",
      "40000/40000 [==============================] - 262s 7ms/step - loss: 0.5229 - accuracy: 0.8288 - val_loss: 0.7495 - val_accuracy: 0.7625\n",
      "Epoch 27/40\n",
      "40000/40000 [==============================] - 276s 7ms/step - loss: 0.5207 - accuracy: 0.8294 - val_loss: 1.0654 - val_accuracy: 0.7722\n",
      "Epoch 28/40\n",
      "40000/40000 [==============================] - 263s 7ms/step - loss: 0.5282 - accuracy: 0.8278 - val_loss: 0.7319 - val_accuracy: 0.7951\n",
      "Epoch 29/40\n",
      "40000/40000 [==============================] - 255s 6ms/step - loss: 0.5287 - accuracy: 0.8300 - val_loss: 0.7264 - val_accuracy: 0.7691\n",
      "Epoch 30/40\n",
      "40000/40000 [==============================] - 260s 6ms/step - loss: 0.5302 - accuracy: 0.8272 - val_loss: 0.7298 - val_accuracy: 0.7867\n",
      "Epoch 31/40\n",
      "40000/40000 [==============================] - 257s 6ms/step - loss: 0.5309 - accuracy: 0.8282 - val_loss: 0.8994 - val_accuracy: 0.7719\n",
      "Epoch 32/40\n",
      "40000/40000 [==============================] - 267s 7ms/step - loss: 0.5328 - accuracy: 0.8295 - val_loss: 0.6977 - val_accuracy: 0.7857\n",
      "Epoch 33/40\n",
      "40000/40000 [==============================] - 258s 6ms/step - loss: 0.5269 - accuracy: 0.8316 - val_loss: 0.8664 - val_accuracy: 0.7798\n",
      "Epoch 34/40\n",
      "40000/40000 [==============================] - 256s 6ms/step - loss: 0.5251 - accuracy: 0.8308 - val_loss: 0.7758 - val_accuracy: 0.7543\n",
      "Epoch 35/40\n",
      "40000/40000 [==============================] - 214s 5ms/step - loss: 0.5302 - accuracy: 0.8310 - val_loss: 0.7939 - val_accuracy: 0.7747\n",
      "Epoch 36/40\n",
      "40000/40000 [==============================] - 207s 5ms/step - loss: 0.5276 - accuracy: 0.8299 - val_loss: 0.7587 - val_accuracy: 0.7775\n",
      "Epoch 37/40\n",
      "40000/40000 [==============================] - 206s 5ms/step - loss: 0.5305 - accuracy: 0.8296 - val_loss: 0.7077 - val_accuracy: 0.7797\n",
      "Epoch 38/40\n",
      "40000/40000 [==============================] - 205s 5ms/step - loss: 0.5249 - accuracy: 0.8312 - val_loss: 0.7070 - val_accuracy: 0.7796\n",
      "Epoch 39/40\n",
      "40000/40000 [==============================] - 183s 5ms/step - loss: 0.5341 - accuracy: 0.8309 - val_loss: 0.7653 - val_accuracy: 0.7772\n",
      "Epoch 40/40\n",
      "40000/40000 [==============================] - 173s 4ms/step - loss: 0.5388 - accuracy: 0.8262 - val_loss: 0.6780 - val_accuracy: 0.7891\n",
      "10000/10000 [==============================] - 15s 2ms/step\n",
      "Test score: 0.7078334088325501\n",
      "Test accuracy: 0.7789000272750854\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 with a Deeper Network at 40 iterations\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 40\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-10 with a Deeper Network at 40 iterations\n",
    "##### Training Set: 82.62%\n",
    "##### Validation: 78.91%\n",
    "##### Test Accuracy: 77.89%\n",
    "##### Gain: 11.17%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:86: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, verbose=1, steps_per_epoch=390)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "390/390 [==============================] - 280s 717ms/step - loss: 1.8820 - accuracy: 0.3150\n",
      "Epoch 2/50\n",
      "390/390 [==============================] - 332s 852ms/step - loss: 1.5658 - accuracy: 0.4319\n",
      "Epoch 3/50\n",
      "390/390 [==============================] - 358s 919ms/step - loss: 1.4327 - accuracy: 0.4858\n",
      "Epoch 4/50\n",
      "390/390 [==============================] - 343s 879ms/step - loss: 1.3469 - accuracy: 0.5177\n",
      "Epoch 5/50\n",
      "390/390 [==============================] - 379s 971ms/step - loss: 1.2896 - accuracy: 0.5417\n",
      "Epoch 6/50\n",
      "390/390 [==============================] - 346s 886ms/step - loss: 1.2403 - accuracy: 0.5618\n",
      "Epoch 7/50\n",
      "390/390 [==============================] - 344s 882ms/step - loss: 1.2048 - accuracy: 0.5752\n",
      "Epoch 8/50\n",
      "390/390 [==============================] - 165s 422ms/step - loss: 1.1727 - accuracy: 0.5871\n",
      "Epoch 9/50\n",
      "390/390 [==============================] - 134s 343ms/step - loss: 1.1553 - accuracy: 0.5941\n",
      "Epoch 10/50\n",
      "390/390 [==============================] - 170s 435ms/step - loss: 1.1290 - accuracy: 0.6061\n",
      "Epoch 11/50\n",
      "390/390 [==============================] - 241s 619ms/step - loss: 1.1149 - accuracy: 0.6095\n",
      "Epoch 12/50\n",
      "390/390 [==============================] - 209s 537ms/step - loss: 1.0970 - accuracy: 0.6189\n",
      "Epoch 13/50\n",
      "390/390 [==============================] - 291s 746ms/step - loss: 1.0917 - accuracy: 0.6178\n",
      "Epoch 14/50\n",
      "390/390 [==============================] - 317s 814ms/step - loss: 1.0843 - accuracy: 0.6241\n",
      "Epoch 15/50\n",
      "390/390 [==============================] - 367s 940ms/step - loss: 1.0811 - accuracy: 0.6255\n",
      "Epoch 16/50\n",
      "390/390 [==============================] - 406s 1s/step - loss: 1.0672 - accuracy: 0.6319\n",
      "Epoch 17/50\n",
      "390/390 [==============================] - 373s 956ms/step - loss: 1.0747 - accuracy: 0.6308\n",
      "Epoch 18/50\n",
      "390/390 [==============================] - 404s 1s/step - loss: 1.0650 - accuracy: 0.6325\n",
      "Epoch 19/50\n",
      "390/390 [==============================] - 396s 1s/step - loss: 1.0640 - accuracy: 0.6348\n",
      "Epoch 20/50\n",
      "390/390 [==============================] - 421s 1s/step - loss: 1.0698 - accuracy: 0.6349\n",
      "Epoch 21/50\n",
      "390/390 [==============================] - 420s 1s/step - loss: 1.0641 - accuracy: 0.6358\n",
      "Epoch 22/50\n",
      "390/390 [==============================] - 421s 1s/step - loss: 1.0699 - accuracy: 0.6344\n",
      "Epoch 23/50\n",
      "390/390 [==============================] - 438s 1s/step - loss: 1.0624 - accuracy: 0.6387\n",
      "Epoch 24/50\n",
      "390/390 [==============================] - 442s 1s/step - loss: 1.0605 - accuracy: 0.6357\n",
      "Epoch 25/50\n",
      "390/390 [==============================] - 412s 1s/step - loss: 1.0605 - accuracy: 0.6378\n",
      "Epoch 26/50\n",
      "390/390 [==============================] - 475s 1s/step - loss: 1.0666 - accuracy: 0.6382\n",
      "Epoch 27/50\n",
      "390/390 [==============================] - 487s 1s/step - loss: 1.0754 - accuracy: 0.6337\n",
      "Epoch 28/50\n",
      "390/390 [==============================] - 402s 1s/step - loss: 1.0630 - accuracy: 0.6367\n",
      "Epoch 29/50\n",
      "390/390 [==============================] - 397s 1s/step - loss: 1.0693 - accuracy: 0.6346\n",
      "Epoch 30/50\n",
      "390/390 [==============================] - 327s 839ms/step - loss: 1.0740 - accuracy: 0.6376\n",
      "Epoch 31/50\n",
      "390/390 [==============================] - 273s 701ms/step - loss: 1.0757 - accuracy: 0.6382\n",
      "Epoch 32/50\n",
      "390/390 [==============================] - 253s 650ms/step - loss: 1.0873 - accuracy: 0.6332\n",
      "Epoch 33/50\n",
      "390/390 [==============================] - 257s 660ms/step - loss: 1.0918 - accuracy: 0.6289\n",
      "Epoch 34/50\n",
      "390/390 [==============================] - 257s 659ms/step - loss: 1.0889 - accuracy: 0.6328\n",
      "Epoch 35/50\n",
      "390/390 [==============================] - 249s 639ms/step - loss: 1.0840 - accuracy: 0.6335\n",
      "Epoch 36/50\n",
      "390/390 [==============================] - 256s 657ms/step - loss: 1.1030 - accuracy: 0.6270\n",
      "Epoch 37/50\n",
      "390/390 [==============================] - 258s 663ms/step - loss: 1.0949 - accuracy: 0.6287\n",
      "Epoch 38/50\n",
      "390/390 [==============================] - 245s 629ms/step - loss: 1.1017 - accuracy: 0.6276\n",
      "Epoch 39/50\n",
      "390/390 [==============================] - 249s 638ms/step - loss: 1.1084 - accuracy: 0.6268\n",
      "Epoch 40/50\n",
      "390/390 [==============================] - 245s 628ms/step - loss: 1.1165 - accuracy: 0.6255\n",
      "Epoch 41/50\n",
      "390/390 [==============================] - 252s 647ms/step - loss: 1.1228 - accuracy: 0.6235\n",
      "Epoch 42/50\n",
      "390/390 [==============================] - 254s 651ms/step - loss: 1.1138 - accuracy: 0.6240\n",
      "Epoch 43/50\n",
      "390/390 [==============================] - 248s 636ms/step - loss: 1.1308 - accuracy: 0.6203\n",
      "Epoch 44/50\n",
      "390/390 [==============================] - 250s 641ms/step - loss: 1.1310 - accuracy: 0.6219\n",
      "Epoch 45/50\n",
      "390/390 [==============================] - 249s 638ms/step - loss: 1.1303 - accuracy: 0.6204\n",
      "Epoch 46/50\n",
      "390/390 [==============================] - 240s 616ms/step - loss: 1.1405 - accuracy: 0.6178\n",
      "Epoch 47/50\n",
      "390/390 [==============================] - 228s 585ms/step - loss: 1.1394 - accuracy: 0.6153\n",
      "Epoch 48/50\n",
      "390/390 [==============================] - 228s 584ms/step - loss: 1.1467 - accuracy: 0.6159\n",
      "Epoch 49/50\n",
      "390/390 [==============================] - 227s 583ms/step - loss: 1.1455 - accuracy: 0.6157\n",
      "Epoch 50/50\n",
      "390/390 [==============================] - 231s 592ms/step - loss: 1.1420 - accuracy: 0.6175\n",
      "10000/10000 [==============================] - 17s 2ms/step\n",
      "Test score: 0.9823134556770324\n",
      "Test accuracy: 0.6628999710083008\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 with Data Augmentation at 50 iterations\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT=5\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 50\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#Augmenting\n",
    "print (\"Augmenting\")\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 40, width_shift_range=0.2,\n",
    "                            height_shift_range = 2.0, zoom_range = 0.2,\n",
    "                            horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "#fit datagen\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape) \n",
    "print(X_train.shape[0], 'train samples') \n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "#model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "#epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "#verbose=VERBOSE)\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE), samples_per_epoch=X_train.shape[0],\n",
    "epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CIFAR-10 with Data Augmentation at 50 iterations\n",
    "##### On this last dataset, I ran into numerous issues trying to implement the code to get it to run properly. The book was a bit confusing on the data augmentation. I was able to work through it with the help of my classmates and their recommendations in the general discussions. As you can see, the test accuracy is affected and is much less than the previous test, or what they had listed in the book.I am not sure why, but the test took hours to complete. I had to redo the test due to Apporto timing out. I was at 30/50 and unfortunately, I had to restart the test.\n",
    "##### Test Accuracy: 66.28%\n",
    "##### Loss: 0.44%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Throughout the years, there has been a rise with concern regarding privacy and ethics in AI. Facial recognition is one of those concerns. It has become a major global issue and there are countries restricting and banning this technology for ethical and privacy concerns. Here in the United States, there are laws passed to regulate facial recognition technology (FRT). Since faces are unable to be encrypted, the data is easily collected and stored in various databases, such as driver’s licenses, social media, mugshots, etc. This causes more of a privacy concern due to the data easily accessible by unauthorized personnel and used to reveal an identity of an individual, which can increase the threat of identity theft, harassment, etc. (Lively, T.K. 2021).\n",
    "###### One of the examples of privacy and ethical concerns with facial recognition was on a social media platform, Facebook, which was removed due to controversial concerns. The technology allowed users to automatically be identified in photos and videos. (Balli, E. 2021). Unfortunately, facial recognition technology isn’t always accurate. There are underlining ethical concerns when the technology isn’t able to distinguish certain racial identities accurately, which can raise concerns on its ability to output images appropriately.\n",
    "###### As AI evolves, it elevates analytics of individuals personal information. The developement of AI and how it distinguishes the data, such as facial recognition raises fundamental ethical and moral issues for society. Even knowing the accuracy of some algorithms are high, there is still a capability of having harmful impacts within humanity and can have harmful consequences. It is still important to keep humans in the loop of AI to monitor and supervise the output of these algorithms (Kippari, I. 2020).\n",
    "###### References\n",
    "###### Balli, E. (2021, November 22). The ethical implications of Facial Recognition Technology. ASU News. Retrieved from https://news.asu.edu/20211117-solutions-ethical-implications-facial-recognition-technology\n",
    "###### Kippari, I. (2020, November 20). Artificial Intelligence, privacy and ethics. BASIS ID. Retrieved from https://www.basisid.com/artificial-intelligence-privacy-and-ethics/#:~:text=As%20artificial%20intelligence%20evolves%2C%20it%20elevates%20analytics%20of,security%20standards%20might%20not%20account%20for%20AI%20capabilities. \n",
    "###### Lively, T. K. (2021, December 1). Facial Recognition in the United States: Privacy Concerns and Legal Developments. ASIS International. Retrieved from https://www.asisonline.org/security-management-magazine/monthly-issues/security-technology/archive/2021/december/facial-recognition-in-the-us-privacy-concerns-and-legal-developments/#:~:text=Facial%20Recognition%20in%20the%20United%20States%3A%20Privacy%20Concerns,FRT%20use.%20...%205%20Federal%20Legislation%20Lacking.%20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
